import os
import openai
import json
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
openai.api_key = os.getenv("OPENAI_API_KEY")

# Intent ë©”íƒ€ ì •ë³´
INTENTS = {
    "market":     "ì‹œí™© Agent: â‘  ì§€ìˆ˜Â·í™˜ìœ¨ ì¡°íšŒ â‘¡ ì „ì£¼ Hot ê¸°ì‚¬ ìš”ì•½Â·í‚¤ì›Œë“œÂ·ê°ì„±",
    "enterprise": "ê¸°ì—…ì •ë³´ Agent: â‘  ì¬ë¬´ì œí‘œÂ·ì§€í‘œ ì¡°íšŒ â‘¡ ì£¼ê°€ ì „ë§ ì˜ˆì¸¡/ê·¼ê±° ì œì‹œ â‘¢ ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½Â·í‚¤ì›Œë“œÂ·ê°ì„±",
    "industry":   "ì‚°ì—…ì •ë³´ Agent: â‘  ì‚°ì—…êµ° ë™í–¥ íŒŒì•… â‘¡ ëŒ€í‘œ ì¢…ëª© ì¶”ì²œ â‘¢ ì¶”ì²œ ì¢…ëª© ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½Â·í‚¤ì›Œë“œÂ·ê°ì„±",
    "personal":   "ê³ ê°ì •ë³´ Agent: â‘  ê³ ê° ê¸°ë³¸ ì •ë³´ ì¡°íšŒ â‘¡ ìœ ì‚¬ ì„±í–¥ ê·¸ë£¹ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ â‘¢ ë³´ìœ  ê¸°ì—…/ì‚°ì—… ì½”ë©˜íŠ¸",
    "fallback":   "ê·¸ ì™¸"
}

# Few-shot examples
few_shot_examples = [
    # market
    ("ì‹œí™©ì •ë³´ê°€ ì–´ë–»ê²Œ ë¼?",     "market"),
    ("ìš”ì¦˜ ì‹œí™© ì–´ë•Œ?",       "market"),
    ("ì „ ì£¼ì˜ ëŒ€í‘œê¸°ì‚¬ ì•Œë ¤ì¤˜","market"),
    ("ìš”ì¦˜ ê²½ì œ ì–´ë•Œ?","market"),
    ("ì „ë°˜ì ì¸ ì‹œí™©ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜","market"),
    ("ì¦ì‹œì •ë³´ Agent","market"),
    # enterprise
    ("ì• í”Œ í–¥í›„ ì „ë§ì´ ì–´ë–»ê²Œ ë¼?",   "enterprise"),
    ("ì•„ë§ˆì¡´ ìš”ì¦˜ ì–´ë•Œ?",    "enterprise"),
    ("ì›”ë§ˆíŠ¸ ê¸°ì—…ì— ëŒ€í•´ì„œ ê¶ê¸ˆí•´",   "enterprise"),
    ("í…ŒìŠ¬ë¼ ê¸°ì—…ì— ëŒ€í•´ ì•Œë ¤ì¤˜",   "enterprise"),
    ("ê¸°ì—…ì •ë³´ Agent",   "enterprise"),
    # industry
    ("ë°˜ë„ì²´ ì‹œì¥ ë¶„ìœ„ê¸° ì–´ë•Œ?",     "industry"),
    ("AI ì‚°ì—…ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜",       "industry"),
    ("ìš”ì¦˜ ì¸ê³µì§€ëŠ¥ ì‚°ì—…ì˜ ì „ë°˜ì ì¸ ìƒí™©ì´ ì–´ë•Œ?", "industry"),
    ("ì‚°ì—…ì •ë³´ Agent", "industry"),
    # personal
    ("xxx ê³ ê°ì´ ë³´ìœ í•œ ì¢…ëª© ì•Œë ¤ì¤˜",     "personal"),
    ("xxx ê³ ê° í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµí•´ì¤˜",      "personal"),
    ("xxx ê³ ê° í¬íŠ¸í´ë¦¬ì˜¤ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜","personal"),
    ("ê³ ê°ë§ì¶¤ Agent","personal"),
]

def classify_intent(text: str) -> str:
    examples = "\n".join(f"{q} â†’ {lbl}" for q, lbl in few_shot_examples)
    prompt = f"""ì•„ë˜ ì˜ˆì‹œë¥¼ ë³´ê³ , ìƒˆ ë¬¸ì¥ì´ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ì¸ì§€ ë¶„ë¥˜í•´ì¤˜. market / enterprise / industry / personal ì¤‘ í•˜ë‚˜ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ fallback ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
{examples}

ë¬¸ì¥: "{text}"
â†’ ì¹´í…Œê³ ë¦¬:
"""
    resp = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role":"user","content":prompt}],
        temperature=0
    )
    label = resp.choices[0].message.content.strip()
    return label if label in INTENTS else "fallback"

EXTRACTION_PROMPT = """ì•„ë˜ ë¬¸ì¥ì„ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ê²°ê³¼ë§Œ ë‚´ë ¤ì¤˜.

- intent: market, enterprise, industry, personal, fallback ì¤‘ í•˜ë‚˜
- intentê°€ \"enterprise\"ë©´:
    â€¢ company_name: (ì˜ˆ: ì—”ë¹„ë””ì•„)
    â€¢ symbol: ë¯¸êµ­ ì£¼ì‹ í‹°ì»¤ (ì˜ˆ: NVDA)
    â€¢ ë§Œì•½ í‹°ì»¤(symbol)ë§Œ ì…ë ¥ëœ ê²½ìš°ì—ë„ í•´ë‹¹ í‹°ì»¤ì˜ ê¸°ì—…ëª…ì„ ì¶”ì¶œí•´ì„œ company_nameì— ë„£ì–´ì¤˜ (ì˜ˆ: \"GS ê¸°ì—… ì£¼ê°€ ì–´ë•Œ?\" â†’ {{ \"intent\": \"enterprise\", \"company_name\": \"goldman sachs\", \"symbol\": \"GS\" }})
- intentê°€ \"industry\"ë©´:
    â€¢ industry_keyword: (ì˜ˆ: ë°˜ë„ì²´)
    â€¢ category: ë‹¤ìŒ ì¤‘ í•˜ë‚˜ â†’ Technology, Consumer Discretionary, Finance, Health Care, Industrials, Energy, Real Estate, Utilities, Consumer Staples, Telecommunications, Basic Materials, Miscellaneous
- intentê°€ \"personal\"ì´ë©´:
    â€¢ customer_name: ë¬¸ì¥ì—ì„œ ì¶”ì¶œí•œ ê³ ê° ì´ë¦„ (ì˜ˆ: ê¹€ì² ìˆ˜)

ë¬¸ì¥: \"{text}\"
â†’
"""

def extract_details(text: str) -> dict:
    prompt = EXTRACTION_PROMPT.format(text=text)
    resp = openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role":"user","content":prompt}],
        temperature=0
    )
    content = resp.choices[0].message.content.strip()
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        return {"intent": "fallback"}

def generate_fallback_answer(text: str) -> str:
    prompt = f"""ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜.

ì§ˆë¬¸: "{text}"
â†’ ë‹µë³€:"""
    resp = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return resp.choices[0].message.content.strip()

def classify_and_extract(text: str) -> dict:
    intent = classify_intent(text)
    if intent in ("enterprise", "industry", "personal"):  # personal ì¶”ê°€
        details = extract_details(text)
        if details.get("intent") == intent:
            return details
    if intent == "fallback":
        answer = generate_fallback_answer(text)
        return {"intent": "fallback", "answer": answer}
    return {"intent": intent}

if __name__ == "__main__":
    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: ë¹ˆ ì¤„ ì…ë ¥)\n")
    while True:
        user_input = input("ğŸ–‹ï¸  ")
        if not user_input.strip():
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        result = classify_and_extract(user_input)
        print("â†’", json.dumps(result, ensure_ascii=False, indent=2), "\n")
